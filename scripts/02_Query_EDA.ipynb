{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7530e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d8b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexión (ajusta si el notebook está dentro de /scripts)\n",
    "conn = sqlite3.connect(\"../database/dodo_supermercado.db\")\n",
    "\n",
    "# Consulta SQL para obtener datos de ventas y supermercados, desde 2023 al 2024\n",
    "# Conocer la demanda en diferentes ciudades y categorías de productos para análisis de series temporales\n",
    "\n",
    "# Consulta SQL con CTE y rango de fechas (2023-2024)\n",
    "# CTE = Common Table Expression/Expresión de Tabla Común\n",
    "query = \"\"\"\n",
    "WITH base AS (\n",
    "    SELECT v.Fecha, v.Categoria, v.Cantidad_Vendida, s.Ciudad, s.Nombre_Supermercado, v.Id_Tienda\n",
    "    FROM Ventas v\n",
    "    JOIN Supermercado s ON v.Id_Tienda = s.Id_Tienda\n",
    "    WHERE v.Fecha >= '2023-01-01' AND v.Fecha < '2025-01-01'\n",
    "    )\n",
    "SELECT * FROM base\n",
    "ORDER BY Ciudad, Fecha;\n",
    "\"\"\"\n",
    "\n",
    "# Carga de datos al DataFrame\n",
    "df = pd.read_sql(query, conn, parse_dates=[\"Fecha\"])\n",
    "conn.close()\n",
    "\n",
    "# Procesamiento de fechas para análisis temporal\n",
    "df[\"Año\"] = df[\"Fecha\"].dt.year\n",
    "df[\"Mes\"] = df[\"Fecha\"].dt.to_period(\"M\")\n",
    "\n",
    "# Verificación de datos cargados\n",
    "print(\"Datos cargados\")\n",
    "print(df.head(6))\n",
    "print(f\"\\n Rango de fechas: {df['Fecha'].min()} a {df['Fecha'].max()}\")\n",
    "print(f\"Ciudades analizadas: {df['Ciudad'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar ventas por Ciudad y Categoria\n",
    "demanda_total = (\n",
    "    df.groupby([\"Ciudad\", \"Categoria\"])[\"Cantidad_Vendida\"].sum().reset_index()\n",
    ")\n",
    "\n",
    "# CATEGORÍA MÁS VENDIDA POR CIUDAD\n",
    "top_categorias = (\n",
    "    demanda_total.sort_values([\"Ciudad\", \"Cantidad_Vendida\"], ascending=[True, False])\n",
    "    .groupby(\"Ciudad\")\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "print(\"=== CATEGORÍA MÁS VENDIDA POR CIUDAD ===\")\n",
    "print(top_categorias)\n",
    "\n",
    "# CATEGORÍA MENOS VENDIDA POR CIUDAD\n",
    "bottom_categorias = (\n",
    "    demanda_total.sort_values([\"Ciudad\", \"Cantidad_Vendida\"], ascending=[True, True])\n",
    "    .groupby(\"Ciudad\")\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "print(\"\\n=== CATEGORÍA MENOS VENDIDA POR CIUDAD ===\")\n",
    "print(bottom_categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f68c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Ciudad por mayor ventas de Categoria a Nivel General/Nacional\n",
    "# Mostrar la ciudad con mayor demanda total de todas las categorías\n",
    "top_ciudad = demanda_total.sort_values(\"Cantidad_Vendida\", ascending=False).head(1)\n",
    "print(\"Ciudad con mayor demanda\")\n",
    "print(top_ciudad)\n",
    "\n",
    "# Top ciudad con menor demanda de Categoria a Nivel General/Nacional\n",
    "# Mostrar la ciudad con menor demanda total de todas las categorías\n",
    "print(\"\\n********************************************** \\n\")\n",
    "menor_demanda_ciudad = demanda_total.sort_values(\n",
    "    \"Cantidad_Vendida\", ascending=True\n",
    ").head(1)\n",
    "print(\"Ciudad con menor demanda\")\n",
    "print(menor_demanda_ciudad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demanda mensual por ciudad y categoría\n",
    "demanda_mensual = (\n",
    "    df.groupby([\"Ciudad\", \"Categoria\", \"Mes\"])[\"Cantidad_Vendida\"].sum().reset_index()\n",
    ")\n",
    "\n",
    "# Visualización de la demanda mensual para la categoría más demandada en cada ciudad\n",
    "ciudades = df[\"Ciudad\"].unique()\n",
    "\n",
    "# Ciclo para graficar la demanda mensual por ciudad\n",
    "# Usamos un gráfico de líneas para cada ciudad\n",
    "for ciudad in ciudades:\n",
    "    data = demanda_mensual[demanda_mensual[\"Ciudad\"] == ciudad]\n",
    "    pivot = data.pivot(\n",
    "        index=\"Mes\", columns=\"Categoria\", values=\"Cantidad_Vendida\"\n",
    "    ).fillna(0)\n",
    "    pivot.plot(figsize=(10, 6), title=f\"Demanda Mensual en {ciudad} (2023-2024)\")\n",
    "    plt.xlabel(\"Mes\")\n",
    "    plt.ylabel(\"Cantidad Vendida\")\n",
    "    plt.legend(title=\"Categoría\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    # Guardar las figuras en \"outputs\" y que en caso de existir sobreescriba así no generamos múltiples archivos\n",
    "    plt.savefig(f\"../outputs/demanda_mensual_{ciudad.replace(' ', '_')}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c32b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking general de categorías por cantidad vendida, suma de todas las ciudades\n",
    "ranking = (\n",
    "    df.groupby([\"Categoria\"])[\"Cantidad_Vendida\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .sort_values(\"Cantidad_Vendida\", ascending=False)\n",
    ")\n",
    "print(\"Ranking general de categorías por cantidad vendida (2023-2024):\")\n",
    "print(ranking)\n",
    "\n",
    "# Visualización del ranking general de categorías\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.bar(ranking[\"Categoria\"], ranking[\"Cantidad_Vendida\"], color=\"skyblue\")\n",
    "plt.title(\"Ranking General de Categorías por Cantidad Vendida (2023-2024)\")\n",
    "plt.xlabel(\"Categoría\")\n",
    "plt.ylabel(\"Cantidad Vendida\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "# Se guarda la figura en \"outputs\" y en caso de existir sobreescriba así no generamos múltiples archivos\n",
    "plt.savefig(\"../outputs/ranking_general_categorias.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las ciudades y categorías\n",
    "casos = [(\"arica\", \"bebidas\"), (\"antofagasta\", \"congelados\")]\n",
    "\n",
    "for ciudad, categoria in casos:\n",
    "    sql = \"\"\"\n",
    "    SELECT v.Fecha, SUM(v.Cantidad_Vendida) AS Cantidad_Vendida\n",
    "    FROM Ventas v\n",
    "    JOIN Supermercado s ON v.Id_Tienda = s.Id_Tienda\n",
    "    WHERE (s.Ciudad) = ?\n",
    "      AND (v.Categoria) = ?\n",
    "      AND v.Fecha BETWEEN '2023-01-01' AND '2024-12-31'\n",
    "    GROUP BY v.Fecha\n",
    "    ORDER BY v.Fecha;\n",
    "    \"\"\"\n",
    "    with sqlite3.connect(\"../database/dodo_supermercado.db\") as conn:\n",
    "        df_diario = pd.read_sql_query(\n",
    "            sql, conn, params=(ciudad, categoria), parse_dates=[\"Fecha\"]\n",
    "        )\n",
    "\n",
    "    print(f\"\\n=== {ciudad.upper()} · {categoria.upper()} ===\")\n",
    "    print(df_diario.head(5))\n",
    "    print(\n",
    "        f\"Total registros: {len(df_diario)}  |  Desde {df_diario['Fecha'].min().date()} hasta {df_diario['Fecha'].max().date()}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec2881",
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio_diario = df_diario[\"Cantidad_Vendida\"].mean()\n",
    "print(f\"\\n=== {ciudad.upper()} · {categoria.upper()} ===\")\n",
    "print(f\"Promedio diario de ventas: {promedio_diario:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diario[\"Mes\"] = df_diario[\"Fecha\"].dt.to_period(\"M\")\n",
    "promedio_mensual = (\n",
    "    df_diario.groupby(\"Mes\")[\"Cantidad_Vendida\"].mean().reset_index().sort_values(\"Mes\")\n",
    ")\n",
    "print(promedio_mensual.head(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2efdfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ciudad, categoria in [(\"arica\", \"bebidas\"), (\"antofagasta\", \"congelados\")]:\n",
    "    sql = \"\"\"\n",
    "    SELECT v.Fecha, SUM(v.Cantidad_Vendida) AS Cantidad_Vendida\n",
    "    FROM Ventas v\n",
    "    JOIN Supermercado s ON v.Id_Tienda = s.Id_Tienda\n",
    "    WHERE (s.Ciudad) = ?\n",
    "      AND (v.Categoria) = ?\n",
    "      AND v.Fecha BETWEEN '2023-01-01' AND '2024-12-31'\n",
    "    GROUP BY v.Fecha\n",
    "    ORDER BY v.Fecha;\n",
    "    \"\"\"\n",
    "\n",
    "    #  Aquí estaba el problema: faltaba volver a leer df_diario en cada iteración\n",
    "    with sqlite3.connect(\"../database/dodo_supermercado.db\") as conn:\n",
    "        df_diario = pd.read_sql_query(\n",
    "            sql, conn, params=(ciudad, categoria), parse_dates=[\"Fecha\"]\n",
    "        )\n",
    "\n",
    "    promedio_diario = df_diario[\"Cantidad_Vendida\"].mean()\n",
    "    variabilidad = df_diario[\"Cantidad_Vendida\"].std()\n",
    "    coef_var = (variabilidad / promedio_diario) * 100\n",
    "\n",
    "    print(f\"\\n=== {ciudad.upper()} · {categoria.upper()} ===\")\n",
    "    print(f\"Promedio diario de ventas: {promedio_diario:.2f}\")\n",
    "    print(f\"Desviación estándar diaria: {variabilidad:.2f}\")\n",
    "    print(f\"Coeficiente de variación: {coef_var:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
